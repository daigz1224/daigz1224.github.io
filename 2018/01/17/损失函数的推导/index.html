<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>损失函数的推导 | DDay's blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/7.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">损失函数的推导</h1><a id="logo" href="/.">DDay's blog</a><p class="description"> GET HANDS DIRTY AND MAKE IT PRETTY.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">损失函数的推导</h1><div class="post-meta">Jan 17, 2018<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-损失函数的作用"><span class="toc-number">1.</span> <span class="toc-text">1. 损失函数的作用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-log-对数损失函数"><span class="toc-number">2.</span> <span class="toc-text">2. log 对数损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-平方损失函数"><span class="toc-number">3.</span> <span class="toc-text">3. 平方损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-指数损失函数"><span class="toc-number">4.</span> <span class="toc-text">4. 指数损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Hinge-损失函数"><span class="toc-number">5.</span> <span class="toc-text">5. Hinge 损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-其他"><span class="toc-number">6.</span> <span class="toc-text">6. 其他</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考文章"><span class="toc-number">7.</span> <span class="toc-text">参考文章</span></a></li></ol></div></div><div class="post-content"><p>log-loss、square-loss、exp-loss 及 hinge-loss 等。</p>
<a id="more"></a>
<h2 id="1-损失函数的作用"><a href="#1-损失函数的作用" class="headerlink" title="1. 损失函数的作用"></a>1. 损失函数的作用</h2><p>损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用 $L(Y, f(x))$ 来表示，损失函数越小，模型的鲁棒性就越好。损失函数是<strong>经验风险函数</strong>的核心部分，也是<strong>结构风险函数</strong>重要组成部分。模型的结构风险函数包括了经验风险项和正则项：</p>
<p>$$\theta^* = \arg \min<em>\theta \frac{1}{N}{}\sum\limits</em>{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\  \Phi(\theta)$$</p>
<p>其中，前面的均值函数表示的是经验风险函数，$L(y_i,f(x_i;\theta))$ 代表的是损失函数，后面的 $Φ(\theta)$ 是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是 L1，也可以是 L2，或者其他的正则函数。整个式子表示的意思是<strong>找到使目标函数最小时的 $θ$ 值</strong></p>
<h2 id="2-log-对数损失函数"><a href="#2-log-对数损失函数" class="headerlink" title="2. log 对数损失函数"></a>2. log 对数损失函数</h2><ul>
<li>逻辑回归（Logistic Regression, LR）</li>
<li>在逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即max F(y, f(x)) —-&gt; min -F(y, f(x)))。从损失函数的视角来看，它就成了log损失函数了。</li>
<li><code>log-loss</code>：</li>
</ul>
<p>$$L(Y,P(Y|X)) = -\log P(Y|X)$$</p>
<ul>
<li>逻辑回归的概率表达式：</li>
</ul>
<p>$$P(Y=1|x)=h<em>{\theta}(x)=g(f(x))=\frac{1}{1+e^{-f(x)}}, \ \log h</em>{\theta}(x)=-\log(1+e^{-f(x)}) $$</p>
<p>$$P(Y=0|x)=1-h<em>{\theta}(x)=1-g(f(x))=\frac{1}{1+e^{f(x)}}, \ \log (1-h</em>{\theta})=-\log(1+e^{f(x)}) $$</p>
<ul>
<li>逻辑回归的的损失函数：</li>
</ul>
<p>$$J(\theta)=-\frac{1}{m}\sum\limits^m<em>{i=1}[y^{(i)}\log h</em>{\theta}(x^{(i)})+(1-y^{(i)})\log (1-h_{\theta}(x^{(i)}))]$$</p>
<h2 id="3-平方损失函数"><a href="#3-平方损失函数" class="headerlink" title="3. 平方损失函数"></a>3. 平方损失函数</h2><ul>
<li>线性回归的最小二乘法（Ordinary Least Squares）。</li>
<li>在线性回归中，它假设样本和噪声都服从高斯分布（中心极限定理），通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：<strong>最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小</strong></li>
<li><code>square-loss</code>：</li>
</ul>
<p>$$L(Y, f(X)) = (Y - f(X))^2$$</p>
<ul>
<li>在实际应用中，通常会使用均方差（MSE）作为一项衡量指标：</li>
</ul>
<p>$$MSE = \frac{1}{n} \sum\limits_{i=1} ^{n} (\tilde{Y_i} - Y_i )^2$$</p>
<h2 id="4-指数损失函数"><a href="#4-指数损失函数" class="headerlink" title="4. 指数损失函数"></a>4. 指数损失函数</h2><ul>
<li>Adaboost</li>
<li><code>exp-loss</code>：</li>
</ul>
<p>$$L(y,f(x))=e^{[-yf(x)]}$$</p>
<ul>
<li>在 Adaboost 中，经过 $m$ 次迭代之后，可以得到 $f_m(x)$ ：</li>
</ul>
<p>$$f<em>m(x)=f</em>{m-1}(x)+\alpha_mG_m(x)$$</p>
<ul>
<li>Adaboost 每次迭代时的目的是为了找到最小化下列式子时的参数 $\alpha$ 和 $G$ ：</li>
</ul>
<p>$$arg\min\limits<em>{\alpha,G}=\sum\limits^N</em>{i=1}e^{[-y<em>i(f</em>{m-1}(x_i))+\alpha G(x_i)]}$$</p>
<h2 id="5-Hinge-损失函数"><a href="#5-Hinge-损失函数" class="headerlink" title="5. Hinge 损失函数"></a>5. Hinge 损失函数</h2><ul>
<li>支持向量机（Support Vector Machine, SVM）</li>
<li><code>hinge-loss</code> ：</li>
</ul>
<p>$$L(y) = \max(0, 1-y\tilde{y}), y=\pm 1$$</p>
<ul>
<li>推导 SVM 的目标函数：</li>
</ul>
<p>$$wx<em>++b\geq1- ξ, \ wx</em>-+b\le-1- ξ, \ 即 \  y_i(wx_i+b)\geq1- ξ$$</p>
<p>$$\min\limits_{w,b}\sum\limits^N_i\max(0,1-y_i(wx_i+b))+\lambda||w||^2$$</p>
<ul>
<li>当 $ξ=1-y_i(wx_i+b)$ ，$\lambda=\frac{1}{2C}$ ,则目标函数就为：</li>
</ul>
<p>$$\min\limits<em>{w,b}\frac{1}{C}(\frac{1}{2}||w||^2+C\sum\limits^N</em>{i=1}ξ_i)$$</p>
<h2 id="6-其他"><a href="#6-其他" class="headerlink" title="6. 其他"></a>6. 其他</h2><ul>
<li><code>0-1 loss</code> ：$L(Y,f(X))=(Y==f(X)) \ ? \ 1 \ : \ 0$</li>
<li><code>abs-loss</code> ：$L(Y,f(X))=|Y-f(X)|$</li>
</ul>
<h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul>
<li><a href="http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/" target="_blank" rel="noopener">机器学习-损失函数</a> 注意文末的图</li>
</ul>
</div><div class="tags"><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2018/01/15/Gluon for MXNet 使用与概念梳理（冗长版）/" class="next">Gluon for MXNet 使用与概念梳理（冗长版）</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><a href="http://dday.top/">
<img src="http://owinowxgh.bkt.clouddn.com/meblack2.jpg" alt="" border="0" style="margin-top:15px; border-radius: 300px;" width="180px"; height="180px"; >
</a></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/项目整理/">项目整理</a><span class="category-list-count">3</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/MXNet/" style="font-size: 15px;">MXNet</a> <a href="/tags/Gluon/" style="font-size: 15px;">Gluon</a> <a href="/tags/AWS/" style="font-size: 15px;">AWS</a> <a href="/tags/Ubuntu/" style="font-size: 15px;">Ubuntu</a> <a href="/tags/PyTorch/" style="font-size: 15px;">PyTorch</a> <a href="/tags/竞赛/" style="font-size: 15px;">竞赛</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/NexT/" style="font-size: 15px;">NexT</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/深度学习/" style="font-size: 15px;">深度学习</a> <a href="/tags/科学上网/" style="font-size: 15px;">科学上网</a> <a href="/tags/Shadowsocks/" style="font-size: 15px;">Shadowsocks</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/理论/" style="font-size: 15px;">理论</a> <a href="/tags/吴恩达/" style="font-size: 15px;">吴恩达</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/C/" style="font-size: 15px;">C++</a> <a href="/tags/conda/" style="font-size: 15px;">conda</a> <a href="/tags/ffmpeg/" style="font-size: 15px;">ffmpeg</a> <a href="/tags/Windows/" style="font-size: 15px;">Windows</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/17/损失函数的推导/">损失函数的推导</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/15/Gluon for MXNet 使用与概念梳理（冗长版）/">Gluon for MXNet 使用与概念梳理（冗长版）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/14/IPV4 IPV6 科学上网/">IPV4 IPV6 科学上网</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/14/激活函数一览/">激活函数一览</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/09/快排，归并，堆排序算法/">快排，归并，堆排序算法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/05/终端命令整理/">终端命令整理</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/01/Kaggle - 120 种狗的图像识别/">Kaggle - 120种狗的图像识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/13/AWS 上使用 MXNet 的环境配置/">AWS 上使用 MXNet 的环境配置</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/15/AI Challenger 场景分类/">AI Challenger 场景分类</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/07/Ubuntu 下 PyTorch 的环境配置/">Ubuntu 下 PyTorch 的环境配置</a></li></ul></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">DDay's blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.1.20/jquery.fancybox.min.css"><script type="text/javascript" color="100,99,98" opacity="0.5" zIndex="-2" count="50" src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>